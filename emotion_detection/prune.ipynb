{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the existing model\n",
    "model = tf.keras.models.load_model('/mnt/data/emotion_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# Define the pruning parameters\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.50,\n",
    "        final_sparsity=0.80,\n",
    "        begin_step=0,\n",
    "        end_step=2000\n",
    "    )\n",
    "}\n",
    "\n",
    "# Apply pruning to the model\n",
    "pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# Compile the pruned model\n",
    "pruned_model.compile(optimizer='adam',\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the pruned model\n",
    "pruned_model.fit(train_dataset, epochs=2, validation_data=validation_dataset)\n",
    "\n",
    "# Strip the pruning wrappers\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "# Save the pruned model\n",
    "model_for_export.save('/mnt/data/pruned_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pruned model to a TensorFlow Lite model with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('/mnt/data/quantized_model.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quantized model and evaluate its accuracy\n",
    "interpreter = tf.lite.Interpreter(model_path='/mnt/data/quantized_model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Function to evaluate the quantized model\n",
    "def evaluate_tflite_model(interpreter, test_dataset):\n",
    "    total, correct = 0, 0\n",
    "    for images, labels in test_dataset:\n",
    "        interpreter.set_tensor(input_details[0]['index'], images)\n",
    "        interpreter.invoke()\n",
    "        predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "        total += labels.shape[0]\n",
    "        correct += (tf.argmax(predictions, axis=1) == labels).numpy().sum()\n",
    "    return correct / total\n",
    "\n",
    "accuracy = evaluate_tflite_model(interpreter, test_dataset)\n",
    "print(f'Accuracy of the pruned and quantized model: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
