{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZo5ac-Tc5KK"
      },
      "source": [
        "# Convert Facenet Keras model to tflite\n",
        "\n",
        "https://github.com/nyoki-mtl/keras-facenet\n",
        "\n",
        "Using this version from github for david sandberg's tf facenet model that has been converted to keras.\n",
        "\n",
        "Otherwise get the keras model from [here](https://drive.google.com/open?id=1aT4DW6k1RqoRmMzCkmysc_qq33leJecF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EwGkiQfTqBT4"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy import spatial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf7RoAkrXVgU"
      },
      "source": [
        "### Upload the keras facenet.h5 model to the machine.\n",
        "\n",
        "*get the keras model from [here](https://drive.google.com/open?id=1aT4DW6k1RqoRmMzCkmysc_qq33leJecF) if you didn't already download it from the steps above.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "aSq91ozoQ3fp",
        "outputId": "d86a4b88-106f-4ceb-a5a5-c06341c8a90b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "bad marshal data (unknown type code)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfacenet_keras.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/CV_Project/venv/lib/python3.8/site-packages/keras/src/saving/saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    231\u001b[0m         filepath,\n\u001b[1;32m    232\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    234\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/CV_Project/venv/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/Desktop/CV_Project/venv/lib/python3.8/site-packages/keras/src/utils/generic_utils.py:102\u001b[0m, in \u001b[0;36mfunc_load\u001b[0;34m(code, defaults, closure, globs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m, binascii\u001b[38;5;241m.\u001b[39mError):\n\u001b[1;32m    101\u001b[0m     raw_code \u001b[38;5;241m=\u001b[39m code\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_unicode_escape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 102\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[43mmarshal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m globs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     globs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()\n",
            "\u001b[0;31mValueError\u001b[0m: bad marshal data (unknown type code)"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('facenet_keras.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE_4LfpTe3u_"
      },
      "source": [
        "# Convert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCvD3DLprI8Y"
      },
      "outputs": [],
      "source": [
        "converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(\"facenet_kera.h5\")\n",
        "tflite_model = converter.convert()\n",
        "open(\"facenet_keras.tflite\", \"wb\").write(tflite_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ran4oFvZbPJr"
      },
      "outputs": [],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huL8gVohxPNF"
      },
      "outputs": [],
      "source": [
        "# download\n",
        "files.download('facenet_keras.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceze6OoM5hZN"
      },
      "source": [
        "# Test it out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8cxsY6x5i4W"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.contrib.lite.Interpreter(model_path=\"facenet_keras.tflite\")\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDGLvJkx5oTc"
      },
      "outputs": [],
      "source": [
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "input_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiYQzB935stN"
      },
      "outputs": [],
      "source": [
        "# Test model on random input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "# change the following line to feed into your own data.\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "print(input_data.shape)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data.shape)\n",
        "print(input_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbJRKYSCR-9R"
      },
      "source": [
        "### Function to extract the embedding of any given input image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MiKmotID01e"
      },
      "outputs": [],
      "source": [
        "def extract_features(filename):\n",
        "  height = input_details[0]['shape'][1]\n",
        "  width = input_details[0]['shape'][2]\n",
        "  img = Image.open(filename)\n",
        "  img = img.resize((width, height))\n",
        "\n",
        "  input_data = np.expand_dims(img, axis=0)\n",
        "  input_data = (np.float32(input_data) - 128) / 128\n",
        "\n",
        "  interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "  interpreter.invoke()\n",
        "  output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "  results = np.squeeze(output_data)\n",
        "  return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwBV-CZcagB_"
      },
      "source": [
        "### Sanity check\n",
        "Do a sanity check to ensure everything is working fine. upload images that you want to compare to see if it makes sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xh2sPQgJLR2"
      },
      "outputs": [],
      "source": [
        "feat1 =  extract_features(\"001.jpeg\")\n",
        "feat2 = extract_features(\"002.jpeg\")\n",
        "feat3 = extract_features(\"003.jpg\")\n",
        "\n",
        "dist1 = 1 - spatial.distance.cosine(feat1,feat2)\n",
        "dist2 = 1 - spatial.distance.cosine(feat1,feat3)\n",
        "print(dist1,dist2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
